---
#- hosts: masters[0]
#  gather_facts: true
#  become: yes
#  vars_files:
#    - ./vars/base_vars.yaml
#  tasks:
    # taint worker_node[0] for prometheus
    - name: Taint node first worker node
      kubernetes.core.k8s_taint:
        kubeconfig: "/etc/kubernetes/admin.conf"
        state: present
        name: "{{ worker0_name }}"
        taints:
        - effect: NoSchedule
          key: "servicegroup"
          value: "monitoring"
    # label worker_node[0] for prometheus
    - name: Label worker node as monitoring roles keeper
      shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf label node "{{ worker0_name }}" node-role.kubernetes.io/prometheus="" node-role.kubernetes.io/grafana="" servicegroup=monitoring 

# make two last worker nodes from inventory as unschedulable - the goal is to dedicate standby nodes
#- hosts: workers[-2]:workers[-1] # I dont know how to make more compact host pattern -__-
#  gather_facts: true
#  become: yes
#  tasks:
    - name: DRAIN two last nodes from workers group to make them "standby nodes"
      kubernetes.core.k8s_drain:
        kubeconfig: "/etc/kubernetes/admin.conf"
        state: cordon
#        name: "{{ ansible_hostname }}"
#      delegate_to: "{{ groups.masters | first }}"
        name: "{{ item }}"
      loop: "{{ groups.workers[(workers_count|int -2):] }}"

    
    - name: Label worker node as standby reserved
      shell: |
        kubectl --kubeconfig=/etc/kubernetes/admin.conf label node "{{ item }}" node-role.kubernetes.io/standby=""
      loop: "{{ groups.workers[(workers_count|int -2):] }}"

#      delegate_to: "{{ groups.masters | first }}"




      
